{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e08430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find cannot import name 'dopri5' from 'assimulo.lib' (c:\\Users\\Uchek\\anaconda3\\envs\\assimulo\\Lib\\site-packages\\assimulo\\lib\\__init__.py)\n",
      "Could not find cannot import name 'rodas' from 'assimulo.lib' (c:\\Users\\Uchek\\anaconda3\\envs\\assimulo\\Lib\\site-packages\\assimulo\\lib\\__init__.py)\n",
      "Could not find cannot import name 'odassl' from 'assimulo.lib' (c:\\Users\\Uchek\\anaconda3\\envs\\assimulo\\Lib\\site-packages\\assimulo\\lib\\__init__.py)\n",
      "Could not find ODEPACK functions.\n",
      "Could not find RADAR5\n",
      "Could not find GLIMDA.\n",
      "Could not find RADAR5\n",
      "Could not find GLIMDA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | Loss: 1.8501\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0755\n",
      "  covar_module.raw_outputscale: grad norm = 0.1239\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.1677\n",
      "Epoch  100 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0005\n",
      "  covar_module.raw_outputscale: grad norm = 0.0004\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0011\n",
      "Epoch  100 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0005\n",
      "  covar_module.raw_outputscale: grad norm = 0.0004\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0011\n",
      "Epoch  200 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  200 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  300 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  300 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  400 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  400 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  500 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  500 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  600 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  600 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  700 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  700 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  800 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  800 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  900 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n",
      "Epoch  900 | Loss: 1.6715\n",
      "  likelihood.noise_covar.raw_noise: grad norm = 0.0000\n",
      "  covar_module.raw_outputscale: grad norm = 0.0000\n",
      "  covar_module.base_kernel.raw_lengthscale: grad norm = 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'r2': {'train': 0.9965724817743717, 'test': 0.7704413362167052},\n",
       " 'mae': {'train': 0.14715219242659863, 'test': 0.8307916654162936},\n",
       " 'rmse': {'train': np.float64(0.19579341441766562),\n",
       "  'test': np.float64(1.1848731933907368)}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import r3.adapters as adapters\n",
    "from sklearn.model_selection import train_test_split\n",
    "import r3.schema as schema\n",
    "import r3.adapters as adapters\n",
    "from r3.models.assimulo import assimulo_model as ivt_model\n",
    "import torch\n",
    "import gpytorch\n",
    "from r3.models.assimulo.gp_assimulo_mean_model import AssimuloMeanGaussianProcessModel\n",
    "\n",
    "\n",
    "X_columns = [\n",
    "    schema.IVTReactionSchema.NTP_M.value,\n",
    "    schema.IVTReactionSchema.T7RNAP_u_uL.value,\n",
    "    schema.IVTReactionSchema.DNA_ug_mL.value,\n",
    "    schema.IVTReactionSchema.Mg2_M.value,\n",
    "    schema.IVTReactionSchema.Spd_M.value,\n",
    "    schema.IVTReactionSchema.TIME_min.value,\n",
    "]\n",
    "\n",
    "y_columns = [schema.IVTReactionSchema.RNA_g_L.value]\n",
    "\n",
    "# Use all the LHS data for the model\n",
    "experimental_conditions, response = adapters.DataPipelineAdapter(\n",
    "    \"egfp_lhs\", verbose=False\n",
    ").get(\n",
    "    X_columns=X_columns,\n",
    "    y_columns=y_columns,\n",
    "    paths_to_merge=[[\"csp_lhs\", \"Definitive Screening Design IVT\"]],\n",
    ")\n",
    "\n",
    "model = ivt_model.AssimuloIVTModel(template=schema.DNATemplates.ANY)\n",
    "predictions = model.predict_rna_yield(\n",
    "    experimental_conditions=experimental_conditions,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# use the residuals of the model to filter out outliers\n",
    "residuals = (\n",
    "    response[schema.IVTReactionSchema.RNA_g_L.value]\n",
    "    - predictions[schema.IVTReactionSchema.RNA_g_L.value]\n",
    ")\n",
    "filtered_indices = residuals[residuals > -4].index\n",
    "filtered_experimental_conditions = experimental_conditions.loc[filtered_indices]\n",
    "filtered_response = response.loc[filtered_indices]\n",
    "\n",
    "\n",
    "X = filtered_experimental_conditions[X_columns].values\n",
    "Y = filtered_response[y_columns].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------- load data ----------------\n",
    "tx = torch.tensor(X_train, dtype=torch.float32)\n",
    "ty = torch.tensor(y_train, dtype=torch.float32).squeeze()  # Ensure 1D\n",
    "\n",
    "# -------- create model -------------\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = AssimuloMeanGaussianProcessModel(\n",
    "    tx,\n",
    "    ty,\n",
    "    X_columns,\n",
    "    likelihood,\n",
    "    is_sequence=True,\n",
    "    autoscaling=True,\n",
    ")\n",
    "\n",
    "# -------- fit ----------------------\n",
    "model.train()\n",
    "likelihood.train()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()\n",
    "    output = model(tx)\n",
    "    loss = -mll(output, ty)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 100 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch:4d} | Loss: {loss.item():.4f}\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f\"  {name}: grad norm = {param.grad.norm().item():.4f}\")\n",
    "\n",
    "# -------- predict ------------------\n",
    "model.eval()\n",
    "\n",
    "# Keep original scale for inputs/outputs; the model handles kernel input scaling internally.\n",
    "adapters.evaluate_model(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assimulo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
